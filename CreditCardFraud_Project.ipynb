{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import keras_tuner\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataframe (1000000, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://media.githubusercontent.com/media/MadMoose02/COMP3608-Project/main/card_transdata.csv')\n",
    "# df = pd.read_csv('card_transdata.csv')\n",
    "\n",
    "print(f'shape of dataframe {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing the independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df.iloc[: , 0:7 ].values)\n",
    "y = df.iloc[: ,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into 3 portions \n",
    "\n",
    "The dataset was then split into 3 different datasets used to train per model .\n",
    "\n",
    "To effectively detect fraud, our foremost goal is to ensure an equitable distribution of positive fraud records across all three datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of fraud records :  87403\n",
      "amount of Non - fraudulent records :  912597\n"
     ]
    }
   ],
   "source": [
    "fraud = df[df['fraud']== 1 ]\n",
    "no_fraud = df[df['fraud'] == 0]\n",
    "\n",
    "print(f'amount of fraud records :  {fraud.shape[0]}')\n",
    "print(f'amount of Non - fraudulent records :  {no_fraud.shape[0]}')\n",
    "\n",
    "\n",
    "#! shrink the dataset to match the fraud records\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87403, 8)\n",
      "(174806, 8)\n",
      "the difference of the dataframes(825194, 8)\n"
     ]
    }
   ],
   "source": [
    "# Down sample the data \n",
    "no_fraud = no_fraud.head(fraud.shape[0])\n",
    "print(no_fraud.shape)\n",
    "\n",
    "\n",
    "exclude_rows = pd.concat([fraud , no_fraud])\n",
    "\n",
    "print(exclude_rows.shape)\n",
    "\n",
    "\n",
    "# represents all the non- fraudulent transactions not used \n",
    "difference_df = df[~df.isin(exclude_rows.to_dict(orient='list')).all(axis=1)]\n",
    "print(f'the difference of the dataframes{difference_df.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size in balanced df : 174806\n",
      "amount allocated to each dataset :58268 \n"
     ]
    }
   ],
   "source": [
    "balanced_df = pd.concat([fraud , no_fraud])\n",
    "balanced_df = shuffle(balanced_df)\n",
    "\n",
    "print(f'size in balanced df : {balanced_df.shape[0]}')\n",
    "\n",
    "\n",
    "even_distr = int(balanced_df.shape[0]/3)\n",
    "print( f'amount allocated to each dataset :{even_distr} ' )\n",
    "\n",
    "\n",
    "df1 = balanced_df.head(even_distr)\n",
    "df2 = balanced_df.iloc[(even_distr+1):(even_distr + even_distr)]\n",
    "df3 = balanced_df.tail(even_distr+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset( df:pd.DataFrame , differenceDf :pd.DataFrame ) -> pd.DataFrame:\n",
    "    fraud = df[df['fraud']== 0 ]\n",
    "    no_fraud = df[df['fraud'] == 1]\n",
    "    print(f'before balance')\n",
    "    print('\\n')\n",
    "    print(f'fraud count is : {fraud.shape[0]} and no - fraud count is : {no_fraud.shape[0]}')\n",
    "\n",
    "\n",
    "    # sample selcts data from the data frame without duplciates\n",
    "    if fraud.shape[0] > no_fraud.shape[0]:\n",
    "        additional_data = difference_df.sample(fraud.shape[0] - no_fraud.shape[0] , replace= False)\n",
    "        no_fraud = pd.concat([no_fraud , additional_data])\n",
    "        print('hi')\n",
    "        print('\\n')\n",
    "        print(f' in fraud count : {fraud.shape[0]} and no - fraud count : {no_fraud.shape[0]}')\n",
    "        merged = pd.concat([no_fraud , fraud])\n",
    "        merged = shuffle(merged)\n",
    "        return merged \n",
    "    elif fraud.shape[0] < no_fraud.shape[0]: \n",
    "        print('smote')\n",
    "        oversample = SMOTE(random_state= 42)\n",
    "        fraud_X = pd.DataFrame(df.iloc[: , 0:7 ].values)\n",
    "        fraud_y = df.iloc[: ,-1].values\n",
    "        fraud_X_val  , fraud_y_val  = oversample.fit_resample(fraud_X , fraud_y)\n",
    "\n",
    "        fraud_X_val = pd.DataFrame(fraud_X_val)\n",
    "        fraud_y_val = pd.DataFrame(fraud_y_val)\n",
    "\n",
    "        mergeXandY = pd.concat([fraud_X_val,fraud_y_val] , axis = 1)\n",
    "\n",
    "        fraud_bal = mergeXandY[mergeXandY.iloc[:, -1] == 0]\n",
    "        no_fraud_bal = mergeXandY[mergeXandY.iloc[:, -1] == 1]\n",
    "\n",
    "        print(f' fraud count {fraud_bal.shape[0]} and no - fraud count{no_fraud_bal.shape[0]}')\n",
    "        print('\\n')\n",
    "        #merged = pd.concat([fraud_bal, no_fraud])\n",
    "        merged = shuffle(mergeXandY)\n",
    "        return merged \n",
    "    else:\n",
    "        print('cu')\n",
    "        merged = pd.concat([fraud , no_fraud])\n",
    "        merged = shuffle(merged)\n",
    "        return merged\n",
    "\n",
    "    #! remember to shuffle after returned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before balance\n",
      "\n",
      "\n",
      "fraud count is : 29233 and no - fraud count is : 29035\n",
      "hi\n",
      "\n",
      "\n",
      " in fraud count : 29233 and no - fraud count : 29233\n",
      "before balance\n",
      "\n",
      "\n",
      "fraud count is : 29158 and no - fraud count is : 29109\n",
      "hi\n",
      "\n",
      "\n",
      " in fraud count : 29158 and no - fraud count : 29158\n",
      "before balance\n",
      "\n",
      "\n",
      "fraud count is : 29011 and no - fraud count is : 29258\n",
      "smote\n",
      " fraud count 29258 and no - fraud count29258\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = balance_dataset(df1 , difference_df)\n",
    "df2 = balance_dataset(df2 , difference_df)\n",
    "df3 = balance_dataset(df3 , difference_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df1.iloc[: , 0:7 ].values)\n",
    "y = df1.iloc[: ,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size= 0.25)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling is optional "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Parameter tuning to determine the amount of nuerons to be used in the hidden layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(hp.Choice('units',[2 , 4 , 8 , 12 , 16 , 20 ,24]) , activation= 'relu') )\n",
    "    model.add(tf.keras.layers.Dense(1 , activation= 'sigmoid'))\n",
    "    model.compile(optimizer = 'SGD',\n",
    "              loss = tf.keras.losses.MeanSquaredError(), \n",
    "              metrics = [tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(build_model, \n",
    "                                 objective='val_recall', \n",
    "                                 max_trials= 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 00m 19s]\n",
      "val_recall: 0.9699848294258118\n",
      "\n",
      "Best val_recall So Far: 0.9705355763435364\n",
      "Total elapsed time: 00h 01m 55s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train , y_train , epochs = 20 , validation_data = (X_test , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_recall\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "units: 4\n",
      "Score: 1.0\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "units: 20\n",
      "Score: 1.0\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "units: 24\n",
      "Score: 0.0\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "units: 12\n",
      "Score: 0.0\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "units: 16\n",
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K - fold cross validation on the nueral network to determine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7 \n",
    "np.random.seed(seed)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10 , shuffle= True , random_state= seed )\n",
    "\n",
    "scores_collection = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - loss: 0.1604 - recall_2: 0.8034\n",
      "Epoch 2/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515us/step - loss: 0.0585 - recall_2: 0.9019\n",
      "Epoch 3/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - loss: 0.0441 - recall_2: 0.9254\n",
      "Epoch 4/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - loss: 0.0385 - recall_2: 0.9364\n",
      "Epoch 5/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - loss: 0.0352 - recall_2: 0.9457\n",
      "Epoch 6/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0324 - recall_2: 0.9501\n",
      "Epoch 7/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - loss: 0.0312 - recall_2: 0.9555\n",
      "Epoch 8/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - loss: 0.0302 - recall_2: 0.9569\n",
      "Epoch 9/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0300 - recall_2: 0.9587\n",
      "Epoch 10/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0282 - recall_2: 0.9618\n",
      "Epoch 11/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0283 - recall_2: 0.9621\n",
      "Epoch 12/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - loss: 0.0282 - recall_2: 0.9620\n",
      "Epoch 13/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - loss: 0.0275 - recall_2: 0.9638\n",
      "Epoch 14/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - loss: 0.0268 - recall_2: 0.9661\n",
      "Epoch 15/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505us/step - loss: 0.0272 - recall_2: 0.9656\n",
      "Epoch 16/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - loss: 0.0267 - recall_2: 0.9679\n",
      "Epoch 17/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484us/step - loss: 0.0254 - recall_2: 0.9685\n",
      "Epoch 18/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502us/step - loss: 0.0263 - recall_2: 0.9679\n",
      "Epoch 19/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - loss: 0.0268 - recall_2: 0.9686\n",
      "Epoch 20/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - loss: 0.0257 - recall_2: 0.9677\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 0.0246 - recall_2: 0.9699\n",
      "compile_metrics: 96.97%\n",
      "Epoch 1/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506us/step - loss: 0.2169 - recall_3: 0.8130\n",
      "Epoch 2/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484us/step - loss: 0.0663 - recall_3: 0.8695\n",
      "Epoch 3/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - loss: 0.0465 - recall_3: 0.9133\n",
      "Epoch 4/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0383 - recall_3: 0.9368\n",
      "Epoch 5/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - loss: 0.0343 - recall_3: 0.9456\n",
      "Epoch 6/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - loss: 0.0323 - recall_3: 0.9500\n",
      "Epoch 7/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.0315 - recall_3: 0.9517\n",
      "Epoch 8/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0312 - recall_3: 0.9539\n",
      "Epoch 9/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0311 - recall_3: 0.9534\n",
      "Epoch 10/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0300 - recall_3: 0.9566\n",
      "Epoch 11/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0292 - recall_3: 0.9604\n",
      "Epoch 12/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0283 - recall_3: 0.9600\n",
      "Epoch 13/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0289 - recall_3: 0.9594\n",
      "Epoch 14/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502us/step - loss: 0.0282 - recall_3: 0.9619\n",
      "Epoch 15/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0285 - recall_3: 0.9626\n",
      "Epoch 16/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - loss: 0.0282 - recall_3: 0.9629\n",
      "Epoch 17/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - loss: 0.0284 - recall_3: 0.9639\n",
      "Epoch 18/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - loss: 0.0275 - recall_3: 0.9637\n",
      "Epoch 19/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0273 - recall_3: 0.9652\n",
      "Epoch 20/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0276 - recall_3: 0.9629\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 0.0260 - recall_3: 0.9642\n",
      "compile_metrics: 96.42%\n",
      "Epoch 1/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - loss: 0.1588 - recall_4: 0.7741\n",
      "Epoch 2/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0587 - recall_4: 0.9126\n",
      "Epoch 3/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0422 - recall_4: 0.9410\n",
      "Epoch 4/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - loss: 0.0358 - recall_4: 0.9495\n",
      "Epoch 5/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0334 - recall_4: 0.9556\n",
      "Epoch 6/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505us/step - loss: 0.0319 - recall_4: 0.9567\n",
      "Epoch 7/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0304 - recall_4: 0.9592\n",
      "Epoch 8/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0292 - recall_4: 0.9621\n",
      "Epoch 9/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0278 - recall_4: 0.9646\n",
      "Epoch 10/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0286 - recall_4: 0.9627\n",
      "Epoch 11/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0278 - recall_4: 0.9654\n",
      "Epoch 12/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0270 - recall_4: 0.9678\n",
      "Epoch 13/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514us/step - loss: 0.0275 - recall_4: 0.9647\n",
      "Epoch 14/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0266 - recall_4: 0.9679\n",
      "Epoch 15/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0266 - recall_4: 0.9682\n",
      "Epoch 16/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496us/step - loss: 0.0258 - recall_4: 0.9675\n",
      "Epoch 17/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0253 - recall_4: 0.9706\n",
      "Epoch 18/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - loss: 0.0254 - recall_4: 0.9689\n",
      "Epoch 19/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496us/step - loss: 0.0251 - recall_4: 0.9703\n",
      "Epoch 20/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0258 - recall_4: 0.9676\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 0.0245 - recall_4: 0.9700\n",
      "compile_metrics: 96.93%\n",
      "Epoch 1/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.1700 - recall_5: 0.6443\n",
      "Epoch 2/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - loss: 0.0602 - recall_5: 0.9007\n",
      "Epoch 3/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - loss: 0.0433 - recall_5: 0.9341\n",
      "Epoch 4/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0368 - recall_5: 0.9466\n",
      "Epoch 5/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505us/step - loss: 0.0346 - recall_5: 0.9513\n",
      "Epoch 6/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0332 - recall_5: 0.9533\n",
      "Epoch 7/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - loss: 0.0324 - recall_5: 0.9561\n",
      "Epoch 8/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502us/step - loss: 0.0312 - recall_5: 0.9567\n",
      "Epoch 9/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - loss: 0.0308 - recall_5: 0.9585\n",
      "Epoch 10/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0292 - recall_5: 0.9612\n",
      "Epoch 11/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - loss: 0.0285 - recall_5: 0.9634\n",
      "Epoch 12/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0288 - recall_5: 0.9635\n",
      "Epoch 13/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0281 - recall_5: 0.9620\n",
      "Epoch 14/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0273 - recall_5: 0.9638\n",
      "Epoch 15/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - loss: 0.0268 - recall_5: 0.9659\n",
      "Epoch 16/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0269 - recall_5: 0.9654\n",
      "Epoch 17/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.0257 - recall_5: 0.9670\n",
      "Epoch 18/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0262 - recall_5: 0.9653\n",
      "Epoch 19/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - loss: 0.0262 - recall_5: 0.9668\n",
      "Epoch 20/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0257 - recall_5: 0.9660\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 0.0250 - recall_5: 0.9665\n",
      "compile_metrics: 96.70%\n",
      "Epoch 1/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - loss: 0.1869 - recall_6: 0.7626\n",
      "Epoch 2/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0740 - recall_6: 0.8647\n",
      "Epoch 3/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - loss: 0.0496 - recall_6: 0.9094\n",
      "Epoch 4/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.0406 - recall_6: 0.9312\n",
      "Epoch 5/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0359 - recall_6: 0.9431\n",
      "Epoch 6/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.0330 - recall_6: 0.9501\n",
      "Epoch 7/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505us/step - loss: 0.0320 - recall_6: 0.9518\n",
      "Epoch 8/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501us/step - loss: 0.0317 - recall_6: 0.9548\n",
      "Epoch 9/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - loss: 0.0297 - recall_6: 0.9592\n",
      "Epoch 10/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0288 - recall_6: 0.9603\n",
      "Epoch 11/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0284 - recall_6: 0.9631\n",
      "Epoch 12/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - loss: 0.0287 - recall_6: 0.9640\n",
      "Epoch 13/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0270 - recall_6: 0.9638\n",
      "Epoch 14/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0274 - recall_6: 0.9661\n",
      "Epoch 15/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - loss: 0.0276 - recall_6: 0.9681\n",
      "Epoch 16/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0267 - recall_6: 0.9679\n",
      "Epoch 17/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - loss: 0.0257 - recall_6: 0.9701\n",
      "Epoch 18/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - loss: 0.0257 - recall_6: 0.9692\n",
      "Epoch 19/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0269 - recall_6: 0.9685\n",
      "Epoch 20/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.0261 - recall_6: 0.9716\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 0.0249 - recall_6: 0.9709\n",
      "compile_metrics: 97.11%\n",
      "Epoch 1/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.1701 - recall_7: 0.6594\n",
      "Epoch 2/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0583 - recall_7: 0.8957\n",
      "Epoch 3/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - loss: 0.0436 - recall_7: 0.9234\n",
      "Epoch 4/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - loss: 0.0377 - recall_7: 0.9358\n",
      "Epoch 5/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - loss: 0.0336 - recall_7: 0.9464\n",
      "Epoch 6/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - loss: 0.0315 - recall_7: 0.9519\n",
      "Epoch 7/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0296 - recall_7: 0.9555\n",
      "Epoch 8/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.0301 - recall_7: 0.9573\n",
      "Epoch 9/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0292 - recall_7: 0.9582\n",
      "Epoch 10/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.0287 - recall_7: 0.9606\n",
      "Epoch 11/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501us/step - loss: 0.0283 - recall_7: 0.9600\n",
      "Epoch 12/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - loss: 0.0271 - recall_7: 0.9636\n",
      "Epoch 13/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0263 - recall_7: 0.9656\n",
      "Epoch 14/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - loss: 0.0269 - recall_7: 0.9644\n",
      "Epoch 15/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - loss: 0.0265 - recall_7: 0.9662\n",
      "Epoch 16/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - loss: 0.0269 - recall_7: 0.9666\n",
      "Epoch 17/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0259 - recall_7: 0.9679\n",
      "Epoch 18/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0267 - recall_7: 0.9661\n",
      "Epoch 19/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507us/step - loss: 0.0246 - recall_7: 0.9685\n",
      "Epoch 20/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - loss: 0.0259 - recall_7: 0.9666\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.0244 - recall_7: 0.9701\n",
      "compile_metrics: 96.92%\n",
      "Epoch 1/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.1454 - recall_8: 0.7141\n",
      "Epoch 2/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0541 - recall_8: 0.9039\n",
      "Epoch 3/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.0421 - recall_8: 0.9286\n",
      "Epoch 4/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0374 - recall_8: 0.9423\n",
      "Epoch 5/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.0342 - recall_8: 0.9480\n",
      "Epoch 6/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - loss: 0.0321 - recall_8: 0.9521\n",
      "Epoch 7/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - loss: 0.0300 - recall_8: 0.9565\n",
      "Epoch 8/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0291 - recall_8: 0.9605\n",
      "Epoch 9/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507us/step - loss: 0.0288 - recall_8: 0.9603\n",
      "Epoch 10/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0286 - recall_8: 0.9623\n",
      "Epoch 11/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - loss: 0.0290 - recall_8: 0.9624\n",
      "Epoch 12/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0284 - recall_8: 0.9636\n",
      "Epoch 13/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0276 - recall_8: 0.9638\n",
      "Epoch 14/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0279 - recall_8: 0.9672\n",
      "Epoch 15/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - loss: 0.0281 - recall_8: 0.9639\n",
      "Epoch 16/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - loss: 0.0266 - recall_8: 0.9658\n",
      "Epoch 17/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - loss: 0.0260 - recall_8: 0.9678\n",
      "Epoch 18/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0273 - recall_8: 0.9652\n",
      "Epoch 19/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0273 - recall_8: 0.9653\n",
      "Epoch 20/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - loss: 0.0266 - recall_8: 0.9658\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 0.0253 - recall_8: 0.9667\n",
      "compile_metrics: 96.65%\n",
      "Epoch 1/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - loss: 0.1606 - recall_9: 0.7808\n",
      "Epoch 2/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0603 - recall_9: 0.9107\n",
      "Epoch 3/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0440 - recall_9: 0.9322\n",
      "Epoch 4/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0374 - recall_9: 0.9419\n",
      "Epoch 5/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - loss: 0.0352 - recall_9: 0.9494\n",
      "Epoch 6/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - loss: 0.0327 - recall_9: 0.9522\n",
      "Epoch 7/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0314 - recall_9: 0.9524\n",
      "Epoch 8/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484us/step - loss: 0.0311 - recall_9: 0.9565\n",
      "Epoch 9/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - loss: 0.0306 - recall_9: 0.9576\n",
      "Epoch 10/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0289 - recall_9: 0.9613\n",
      "Epoch 11/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.0291 - recall_9: 0.9622\n",
      "Epoch 12/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0293 - recall_9: 0.9637\n",
      "Epoch 13/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496us/step - loss: 0.0283 - recall_9: 0.9619\n",
      "Epoch 14/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0279 - recall_9: 0.9626\n",
      "Epoch 15/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.0276 - recall_9: 0.9634\n",
      "Epoch 16/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - loss: 0.0272 - recall_9: 0.9644\n",
      "Epoch 17/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - loss: 0.0268 - recall_9: 0.9675\n",
      "Epoch 18/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485us/step - loss: 0.0279 - recall_9: 0.9648\n",
      "Epoch 19/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0280 - recall_9: 0.9653\n",
      "Epoch 20/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - loss: 0.0256 - recall_9: 0.9698\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.0253 - recall_9: 0.9682\n",
      "compile_metrics: 96.78%\n",
      "Epoch 1/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.1839 - recall_10: 0.9301\n",
      "Epoch 2/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - loss: 0.0733 - recall_10: 0.8731\n",
      "Epoch 3/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0507 - recall_10: 0.9066\n",
      "Epoch 4/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0401 - recall_10: 0.9319\n",
      "Epoch 5/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496us/step - loss: 0.0370 - recall_10: 0.9418\n",
      "Epoch 6/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502us/step - loss: 0.0347 - recall_10: 0.9465\n",
      "Epoch 7/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0327 - recall_10: 0.9515\n",
      "Epoch 8/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0322 - recall_10: 0.9522\n",
      "Epoch 9/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0307 - recall_10: 0.9550\n",
      "Epoch 10/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - loss: 0.0301 - recall_10: 0.9572\n",
      "Epoch 11/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - loss: 0.0306 - recall_10: 0.9574\n",
      "Epoch 12/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0296 - recall_10: 0.9573\n",
      "Epoch 13/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - loss: 0.0288 - recall_10: 0.9599\n",
      "Epoch 14/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0290 - recall_10: 0.9600\n",
      "Epoch 15/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0286 - recall_10: 0.9612\n",
      "Epoch 16/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0289 - recall_10: 0.9610\n",
      "Epoch 17/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - loss: 0.0290 - recall_10: 0.9625\n",
      "Epoch 18/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501us/step - loss: 0.0273 - recall_10: 0.9646\n",
      "Epoch 19/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496us/step - loss: 0.0280 - recall_10: 0.9621\n",
      "Epoch 20/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501us/step - loss: 0.0274 - recall_10: 0.9643\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.0260 - recall_10: 0.9638\n",
      "compile_metrics: 96.35%\n",
      "Epoch 1/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.1716 - recall_11: 0.8013\n",
      "Epoch 2/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483us/step - loss: 0.0698 - recall_11: 0.8856\n",
      "Epoch 3/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - loss: 0.0478 - recall_11: 0.9221\n",
      "Epoch 4/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0390 - recall_11: 0.9412\n",
      "Epoch 5/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - loss: 0.0347 - recall_11: 0.9497\n",
      "Epoch 6/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0326 - recall_11: 0.9550\n",
      "Epoch 7/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0309 - recall_11: 0.9614\n",
      "Epoch 8/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0310 - recall_11: 0.9595\n",
      "Epoch 9/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - loss: 0.0307 - recall_11: 0.9620\n",
      "Epoch 10/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0288 - recall_11: 0.9622\n",
      "Epoch 11/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - loss: 0.0287 - recall_11: 0.9624\n",
      "Epoch 12/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0275 - recall_11: 0.9663\n",
      "Epoch 13/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0275 - recall_11: 0.9663\n",
      "Epoch 14/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0268 - recall_11: 0.9670\n",
      "Epoch 15/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0276 - recall_11: 0.9655\n",
      "Epoch 16/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - loss: 0.0273 - recall_11: 0.9663\n",
      "Epoch 17/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.0273 - recall_11: 0.9669\n",
      "Epoch 18/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483us/step - loss: 0.0262 - recall_11: 0.9679\n",
      "Epoch 19/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 0.0267 - recall_11: 0.9681\n",
      "Epoch 20/20\n",
      "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - loss: 0.0261 - recall_11: 0.9681\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.0248 - recall_11: 0.9707\n",
      "compile_metrics: 97.09%\n",
      "96.79% (+/- 0.25%)\n"
     ]
    }
   ],
   "source": [
    "for train , test in kfold.split(X , y):\n",
    "    model =  tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(20, activation='relu') , \n",
    "    tf.keras.layers.Dense(1 , activation= 'sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer = 'SGD',\n",
    "              loss = tf.keras.losses.MeanSquaredError(), \n",
    "              metrics = [tf.keras.metrics.Recall()])\n",
    "\n",
    "    model.fit(X_train,y_train , epochs= 20)\n",
    "    score = model.evaluate(X_test,y_test)\n",
    "\n",
    "    scores_collection.append(score[1] * 100 )\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(scores_collection), np.std(scores_collection)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model =  tf.keras.models.Sequential([\n",
    "\n",
    "    #Dense layer , number of neurons and activation\n",
    "    tf.keras.layers.Dense(1 , activation='relu'),\n",
    "    #output , numnber of nuerons in output layer is no.of classes \n",
    "    tf.keras.layers.Dense(1 , activation= 'sigmoid')\n",
    "\n",
    "    #each hidden layer has one nueron \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss_function = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(optimizer = 'SGD',\n",
    "              loss = loss_function, \n",
    "              metrics = [tf.keras.metrics.Recall()])\n",
    "\n",
    "model.fit(X_train,y_train , epochs= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_hat = model.predict(X_test)\n",
    "\n",
    "classifying the raw neural net values\n",
    "y_pred_thresholded = np.where(y_hat > 0.5, 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conMatrix = confusion_matrix(y_test , y_pred_thresholded)\n",
    "accuracyScore = accuracy_score(y_test , y_hat)\n",
    "\n",
    "print(conMatrix)\n",
    "\n",
    "print(f'Accuracy {accuracyScore}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df2.iloc[: , 0:7 ].values)\n",
    "y = df2.iloc[: ,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size= 0.25)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4363 epochs took 19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4367 epochs took 19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4372 epochs took 19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4338 epochs took 19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4370 epochs took 19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3959 epochs took 17 seconds\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4357 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4360 epochs took 16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4366 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4331 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4363 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3953 epochs took 15 seconds\n",
      "[LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4367 epochs took 19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4370 epochs took 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4376 epochs took 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4342 epochs took 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4373 epochs took 19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3964 epochs took 18 seconds\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4364 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4367 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4373 epochs took 16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4338 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4370 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3961 epochs took 15 seconds\n",
      "[LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4368 epochs took 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4372 epochs took 19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4377 epochs took 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4343 epochs took 19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4375 epochs took 19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3966 epochs took 17 seconds\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4366 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4369 epochs took 16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4375 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4341 epochs took 16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4372 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3964 epochs took 15 seconds\n",
      "[LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4369 epochs took 19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4372 epochs took 21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(max_iter=10000 , verbose= 1)\n",
    "\n",
    "param_grid= { \n",
    "    'C':[0.1 , 0.2 , 0.3 , 0.4 ] , \n",
    "    'penalty':['l1' , 'l2'] , \n",
    "    'solver':['liblinear' , 'saga']\n",
    "    }\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=logit , param_grid=param_grid , cv = 6)\n",
    "grid_search.fit(X_train , y_train)\n",
    "\n",
    "\n",
    "print('tuned hyper param ' ,grid_search.best_params_ )\n",
    "print(\"accuracy :\",grid_search.best_score_)\n",
    "#y_hat = logit.predict(X_test)\n",
    "\n",
    "#print(f'Accuraccy for logit is {accuracy_score(y_test,y_hat)}')\n",
    "\n",
    "\n",
    "#print(f'confusion_matrix for logit is {confusion_matrix(y_test,y_hat)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 466 6792]\n",
      " [ 143 7145]]\n",
      "0.5232366286264265\n"
     ]
    }
   ],
   "source": [
    "#using cardTransData1 \n",
    "\n",
    "t_logit = LogisticRegression()\n",
    "\n",
    "t_logit.fit(X_train , y_train)\n",
    "\n",
    "y_nw = t_logit.predict(X_test)\n",
    "\n",
    "print(f'{confusion_matrix(y_test , y_nw)}')\n",
    "print(f'{accuracy_score(y_test , y_nw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tuned logistic regression model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7121  137]\n",
      " [ 428 6860]]\n"
     ]
    }
   ],
   "source": [
    "best_logit = LogisticRegression(C =0.3 , penalty='l1', solver = 'liblinear')\n",
    "\n",
    "best_logit.fit(X_train , y_train)\n",
    "\n",
    "y_nw = best_logit.predict(X_test)\n",
    "\n",
    "print(f'{confusion_matrix(y_test , y_nw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df3.iloc[: , 0:7 ].values)\n",
    "y = df3.iloc[: ,-1].values\n",
    "\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size= 0.25)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m----> 3\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m      5\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(y_test,y_hat)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "y_hat = rf.predict(X_test)\n",
    "\n",
    "print(f'Accuracy {accuracy_score(y_test,y_hat)}')\n",
    "\n",
    "print(f'confusion matrix {confusion_matrix(y_test,y_hat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = StandardScaler() \n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "clf = LinearSVC(max_iter=200000, dual = False)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "print('y')\n",
    "\n",
    "y_hat = clf.predict(X_test)\n",
    "print('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuraccy for SVM is 0.234472\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for SVM is {accuracy_score(y_test,y_hat)}')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
